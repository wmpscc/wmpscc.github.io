<!DOCTYPE html>
<html lang="zh-CN">

  
<head>
  <meta charset="utf-8">
  <meta name="baidu-site-verification" content="5CxA73ejrD">
  <meta name="author" content="è‘£æ²…é‘«, yuanxin.me@gmail.com">
  
  
  
  <title>è·¯é¢è£‚ç¼åˆ†å‰²ç›¸å…³è®ºæ–‡ç¬”è®° | é¸¢å°¾èŠ±å¼€</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="è®ºæ–‡,ç¬”è®°,">
  

  <script>
    console.log('\n%c Hexo-theme-bmw v4.0 ' + '%c ğŸ‰ https://github.com/dongyuanxin/theme-bmw ğŸ‰\n' + '\n%c View demo online ' + '%c ğŸ” https://ishero.net/ ğŸ”  \n' , 'color: #fadfa3; background: #030307; padding:3px 0;', '', 'color: #fadfa3; background: #030307; padding:3px 0;', '');
  </script>

  
    <meta name="description" content="CV&amp;MLæŠ€æœ¯æ–°äººçš„åšå®¢ï¼Œè®°å½•æˆ‘çš„å­¦ä¹ æˆé•¿è¿‡ç¨‹ï¼">
  

  

  
    <link rel="icon" href="/images/favicon.ico">
    <link rel="apple-touch-icon" href="/images/touch-icon.png">
  

  <link href="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.css" rel="stylesheet">
  
<link rel="stylesheet" href="/css/base.css">
<link rel="stylesheet" href="/icon/iconfont.css">
<link rel="stylesheet" href="/css/github-markdown.css">
<link rel="stylesheet" href="/css/highlight.css">


  
<script src="/js/util.js"></script>
<script src="/js/valine.min.js"></script>


  
    
<link rel="stylesheet" href="/custom/style.css">

  

  

  
    <link href="https://cdn.bootcss.com/social-share.js/1.0.16/css/share.min.css" rel="stylesheet">
  
  
  <script src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js" async></script>
  
  
    <script src="//cdn.jsdelivr.net/npm/leancloud-storage@3.11.0/dist/av-min.js"></script>
  

<meta name="generator" content="Hexo 4.2.0"></head>


  <body>
    <meta name="referrer" content="no-referrer">

    

    <div id="app">

      <div class="header-wrap">
  <header>
    <div class="site-brand">
      <div class="site-title">
        <a href="/">isHero.net</a>
      </div>
    </div>
    <nav class="site-navigation">
      <ul class="nav-menu">
      
        <li class="nav-item" data-path="/">
          
            <a href="/" target="_self">
              ä¸»é¡µ
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/archives/">
          
            <a href="/archives/" target="_self">
              å½’æ¡£
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/categories/">
          
            <a href="/categories/" target="_self">
              åˆ†ç±»
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/tags/">
          
            <a href="/tags/" target="_self">
              æ ‡ç­¾
            </a>
          
        </li>
      
        <li class="nav-item" data-path="/friends/">
          
            <a href="/friends/" target="_self">
              å‹é“¾
            </a>
          
        </li>
      
        <li class="nav-item" data-path="">
          
            <a href="javascript:void(0);" v-else="">å¯»æˆ‘</a>
            <ul class="nav-menu--dropdown">
              
                <li>
                  <a href="https://github.com/wmpscc" target="_blank" rel="external nofollow noopener noreferrer">
                    Github
                  </a>
                </li>
              
                <li>
                  <a href="https://www.jianshu.com/u/fde2534da842" target="_blank" rel="external nofollow noopener noreferrer">
                    ç®€ä¹¦
                  </a>
                </li>
              
                <li>
                  <a href="https://toutiao.io/subjects/345107" target="_blank" rel="external nofollow noopener noreferrer">
                    å¼€å‘è€…å¤´æ¡
                  </a>
                </li>
              
            </ul>
          
        </li>
      
      </ul>
    </nav>
    <i class="iconfont icon-menu"></i>
  </header>
</div>

<script>
  let links = document.querySelectorAll('.nav-item');
  for(let link of links){
    let childrenLink = link.querySelector('ul');
    link.addEventListener('mouseenter', () => {
      if(childrenLink) {
        childrenLink.className = "nav-menu--dropdown active";
      }
    })
    link.addEventListener('mouseleave', () => {
      if(childrenLink) {
        childrenLink.className = "nav-menu--dropdown";
      }
    })
  }
  let rootRealPath = getRealPath(window.location.pathname, true);
  for(let link of links) {
    let linkPath = link.getAttribute("data-path");
    if(linkPath && getRealPath(linkPath, true) === rootRealPath) {
      link.className = "nav-item hover";
    }
  }

  let iconMenu = document.querySelector("i.iconfont.icon-menu"),
    iconMenuClicked = false;
  let navDOM = document.querySelector("nav.site-navigation");
  iconMenu.addEventListener("click", () => {
    iconMenuClicked 
      ? navDOM.className = "site-navigation active"
      : navDOM.className = "site-navigation";
    iconMenuClicked = !iconMenuClicked;
  })
</script>

      








<div class="container post-index">

  

<div class="post">
  <h1 class="article-title">
    <span>è·¯é¢è£‚ç¼åˆ†å‰²ç›¸å…³è®ºæ–‡ç¬”è®°</span>
  </h1>
  <meta name="referrer" content="no-referrer">
  <div class="article-top-meta">
    <span>
      å‘å¸ƒ : 
      2020-01-29
    </span>
    
      <span>
        åˆ†ç±» : 
          <a href="/categories/%E8%AE%BA%E6%96%87/">
            è®ºæ–‡
          </a>
      </span>
    
    
      <span>
        æµè§ˆ : <span class="article-timer" data-identity="è·¯é¢è£‚ç¼åˆ†å‰²ç›¸å…³è®ºæ–‡ç¬”è®°.html"></span>
      </span>
    
  </div>

  

  <div class="article-content">
    <div class="markdown-body">
      <p>æœ€è¿‘åœ¨åšè·¯é¢è£‚ç¼åˆ†å‰²ç›¸å…³å·¥ä½œï¼Œè¿™é‡Œåšç›¸å…³è®ºæ–‡çš„è®°å½•ã€‚<br><a href="http://ishero.net/Pavement%20Crack%20Segmentation%20Paper.html">paper ç›®å½•</a></p>
<h1 id="é˜…è¯»æ‘˜è¦"><a href="#é˜…è¯»æ‘˜è¦" class="headerlink" title="é˜…è¯»æ‘˜è¦"></a>é˜…è¯»æ‘˜è¦</h1><h2 id="1-A-Deep-Neural-Networks-Approach-for-Pixel-Level-Runway-Pavement-Crack-Segmentation-Using-Drone-Captured-Images"><a href="#1-A-Deep-Neural-Networks-Approach-for-Pixel-Level-Runway-Pavement-Crack-Segmentation-Using-Drone-Captured-Images" class="headerlink" title="1.A Deep Neural Networks Approach for Pixel-Level Runway Pavement Crack Segmentation Using Drone-Captured Images"></a>1.A Deep Neural Networks Approach for Pixel-Level Runway Pavement Crack Segmentation Using Drone-Captured Images</h2><p><a href="https://arxiv.org/abs/2001.03257" target="_blank" rel="external nofollow noopener noreferrer">arXiv:2001.03257</a>  [<a href="./pdf/2001.03257">pdf</a>] cs.CV eess.IV<br>Authors: <a href="https://arxiv.org/search/?searchtype=author&query=Jiang%2C+L" target="_blank" rel="external nofollow noopener noreferrer">Liming Jiang</a>, <a href="https://arxiv.org/search/?searchtype=author&query=Xie%2C+Y" target="_blank" rel="external nofollow noopener noreferrer">Yuanchang Xie</a>, <a href="https://arxiv.org/search/?searchtype=author&query=Ren%2C+T" target="_blank" rel="external nofollow noopener noreferrer">Tianzhu Ren</a><br>Abstract: Pavement conditions are a critical aspect of asset management and directly affect safety. This study introduces a deep neural network method called U-Net for pavement crack segmentation based on drone-captured images to reduce the cost and time needed for airport runway inspection. The proposed approach can also be used for highway pavement conditions assessment during off-peak periods when there are few vehicles on the road. In this study, runway pavement images are collected using drone at various heights from the Fitchburg Municipal Airport (FMA) in Massachusetts to evaluate their quality and applicability for crack segmentation, from which an optimal height is determined. Drone images captured at the optimal height are then used to evaluate the crack segmentation performance of the U-Net model. Deep learning methods typically require a huge set of annotated training datasets for model development, which can be a major obstacle for their applications. An online annotated pavement image dataset is used together with the FMA data to train the U-Net model. The results show that U-Net performs well on the FMA testing data even with limited FMA training images, suggesting that it has good generalization ability and great potential to be used for both airport runways and highway pavements.<br>Submitted 9 January, 2020; originally announced January 2020.<br>Comments: 13 pages, 5 figures</p>
<h3 id="1-ç®€è¿°"><a href="#1-ç®€è¿°" class="headerlink" title="1.ç®€è¿°"></a>1.ç®€è¿°</h3><p>æå‡ºäº†ä¸€ç§åŸºäºæ— äººæœºå›¾åƒçš„è·¯é¢è£‚ç¼æ·±åº¦ç¥ç»ç½‘ç»œ U-Net åˆ†å‰²æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä¹Ÿå¯åº”ç”¨äºè½¦è¾†è¾ƒå°‘çš„éé«˜å³°æœŸå…¬è·¯è·¯é¢çŠ¶å†µè¯„ä¼°ã€‚<br>ç»“æœè¡¨æ˜ï¼Œåœ¨ FMA è®­ç»ƒå›¾åƒæœ‰é™çš„æƒ…å†µä¸‹ U-Net åœ¨ FMA æµ‹è¯•æ•°æ®ä¸Šè¡¨ç°è‰¯å¥½ï¼Œå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨æœºåœºè·‘é“å’Œé«˜é€Ÿå…¬è·¯è·¯é¢ä¸Šéƒ½æœ‰å¾ˆå¤§çš„åº”ç”¨æ½œåŠ›ã€‚</p>
<h3 id="2-æ•°æ®é›†"><a href="#2-æ•°æ®é›†" class="headerlink" title="2.æ•°æ®é›†"></a>2.æ•°æ®é›†</h3><p>ä½¿ç”¨æ— äººæœºåœ¨ç¾å›½é©¬è¨è¯¸å¡å·è´¹å¥‡å ¡æœºåœºï¼ˆFMAï¼‰çš„ä¸åŒé«˜åº¦é‡‡é›†çš„è·‘é“è·¯é¢å›¾åƒã€<br>ä½¿ç”¨åœ¨çº¿æ ‡æ³¨çš„è·¯é¢æ•°æ®é›†å’Œ FMA æ•°æ®å¯¹ U-Net æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚<br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289277486-15155b8e-97df-4cda-82d5-902a1b421b96.png#align=left&display=inline&height=259&name=1579509382227.png&originHeight=259&originWidth=1199&size=37310&status=done&style=none&width=1199" alt="1579509382227.png"><br>ä½¿ç”¨æ— äººæœºæ‹æ‘„å›¾ç‰‡å°ºå¯¸ä¸º(5472 pixels x 3648 pixels) ï¼Œå°†å…¶åˆ’åˆ†ä¸º(256 pixels x 256 pixels)çš„å—ï¼Œå¯¹å…¶è¿›è¡Œæ ‡æ³¨ã€‚</p>
<h3 id="3-æ–¹æ³•"><a href="#3-æ–¹æ³•" class="headerlink" title="3.æ–¹æ³•"></a>3.æ–¹æ³•</h3><ul>
<li>U-Net</li>
</ul>
<p>åœ¨å°†å…¶åº”ç”¨äºåˆ†ææ— äººæœºæ”¶é›†çš„è·‘é“è·¯é¢å›¾åƒä¹‹å‰ï¼Œå¯¹åŸå§‹ u å½¢ç½‘è¿›è¡Œäº†ä¸€äº›è¶…å‚æ•°è°ƒæ•´ã€‚åœ¨(4,5)çš„å¯å‘ä¸‹ï¼Œè€ƒè™‘æ›´æ·±å±‚æ¬¡çš„ç»“æ„ï¼Œæ¯ä¸ªå·ç§¯å±‚çš„é€šé“æ•°å¢åŠ  0.5 å€ï¼Œæé«˜æ¨¡å‹æ‹Ÿåˆå’Œæ³›åŒ–èƒ½åŠ›ã€‚å¦å¤–ï¼Œå°†å›¾åƒè¾“å…¥ç»´æ•°è®¾ç½®ä¸º 256Ã—256 åƒç´ ã€‚</p>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289289789-9bbb7735-aa09-4ea4-b980-28c1f54e7bda.png#align=left&display=inline&height=830&name=1579507355352.png&originHeight=830&originWidth=1291&size=145073&status=done&style=none&width=1291" alt="1579507355352.png"></p>
<ul>
<li>Data Augmentation</li>
</ul>
<p>ä½¿ç”¨æ•°æ®å¢å¼ºï¼Œè¿›ä¸€æ­¥å¢åŠ è®­ç»ƒé›†æ•°é‡ã€‚</p>
<ul>
<li>Hyperparameters</li>
</ul>
<p>ä¼˜åŒ–å™¨ï¼šAdam ä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡ä¸º.0001ã€‚</p>
<p>æŸå¤±å‡½æ•°ï¼šbinary cross entropy</p>
<p>æ¿€æ´»å‡½æ•°ï¼šæœ€åä¸€å±‚ä½¿ç”¨ Sigmoid å‡½æ•°ï¼Œå…¶ä»–å±‚ä½¿ç”¨ ReLu æ¿€æ´»å‡½æ•°ã€‚</p>
<p>è®­ç»ƒé›†(training episodes)è®¾ä¸º 1000ã€‚</p>
<p>Batch size:5</p>
<h4 id="è®­ç»ƒ"><a href="#è®­ç»ƒ" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h4><p>åœ¨ Crack500 è®­ç»ƒé›†ä¸Šè®­ç»ƒï¼Œåœ¨ Crack500 å’Œ FMA æµ‹è¯•é›†ä¸Šæµ‹è¯•ã€Crack500&amp;FMA æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œåœ¨ FMA æµ‹è¯•é›†ä¸Šæµ‹è¯•ã€‚<br>æ„é€  Crack500&amp;FMA æ•°æ®é›†æ˜¯å› ä¸ºï¼ŒFMA æ•°æ®é›†æ•°é‡å¤ªå°‘äº†ï¼Œä¸è¶³ä»¥è®­ç»ƒ UNet æ¨¡å‹ã€‚</p>
<h3 id="4-æ•ˆæœ"><a href="#4-æ•ˆæœ" class="headerlink" title="4.æ•ˆæœ"></a>4.æ•ˆæœ</h3><p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289302962-7fb8b6fd-3a34-4176-9756-26ffc17b29e3.png#align=left&display=inline&height=382&name=1579510998291.png&originHeight=382&originWidth=1221&size=91702&status=done&style=none&width=1221" alt="1579510998291.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289312406-c0f9ca82-6eaf-48b0-b866-8c6e730f8cb9.png#align=left&display=inline&height=672&name=1579511017802.png&originHeight=672&originWidth=1296&size=397686&status=done&style=none&width=1296" alt="1579511017802.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289322306-14130c4e-ad0b-4d3f-8869-e7c9ee0d5d91.png#align=left&display=inline&height=746&name=1579511036262.png&originHeight=746&originWidth=1298&size=498011&status=done&style=none&width=1298" alt="1579511036262.png"><br>U-Net_Crack500 æ¨¡å‹è¿˜åœ¨é«˜é€Ÿå…¬è·¯ï¼Œç”±æ¿€å…‰è·¯é¢æ‰«æç³»ç»Ÿé‡‡é›†çš„å›¾åƒï¼Œæœ‰ç€ä¸é”™çš„è¡¨ç°ã€‚<br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289332573-622fd54b-8344-4496-8942-db7555161a6d.png#align=left&display=inline&height=573&name=1579511182475.png&originHeight=573&originWidth=1305&size=275154&status=done&style=none&width=1305" alt="1579511182475.png"></p>
<h2 id="2-Automated-Pavement-Crack-Segmentation-Using-Fully-Convolutional-U-Net-with-a-Pretrained-ResNet-34-Encoder"><a href="#2-Automated-Pavement-Crack-Segmentation-Using-Fully-Convolutional-U-Net-with-a-Pretrained-ResNet-34-Encoder" class="headerlink" title="2.Automated Pavement Crack Segmentation Using Fully Convolutional U-Net with a Pretrained ResNet-34 Encoder"></a>2.Automated Pavement Crack Segmentation Using Fully Convolutional U-Net with a Pretrained ResNet-34 Encoder</h2><p><a href="https://arxiv.org/abs/2001.01912" target="_blank" rel="external nofollow noopener noreferrer">arXiv:2001.01912</a>  [<a href="./pdf/2001.01912">pdf</a>]  cs.CV<br>Authors: <a href="https://arxiv.org/search/?searchtype=author&query=Lau%2C+S+L+H" target="_blank" rel="external nofollow noopener noreferrer">Stephen L. H. Lau</a>, <a href="https://arxiv.org/search/?searchtype=author&query=Wang%2C+X" target="_blank" rel="external nofollow noopener noreferrer">Xin Wang</a>, <a href="https://arxiv.org/search/?searchtype=author&query=Yang%2C+X" target="_blank" rel="external nofollow noopener noreferrer">Xu Yang</a>, <a href="https://arxiv.org/search/?searchtype=author&query=Chong%2C+E+K+P" target="_blank" rel="external nofollow noopener noreferrer">Edwin K. P. Chong</a><br>Abstract: Automated pavement crack segmentation is a challenging task because of inherent irregular patterns and lighting conditions, in addition to the presence of noise in images. Conventional approaches require a substantial amount of feature engineering to differentiate crack regions from non-affected regions. In this paper, we propose a deep learning technique based on a convolutional neural network to perform segmentation tasks on pavement crack images. Our approach requires minimal feature engineering compared to other machine learning techniques. The proposed neural network architecture is a modified U-Net in which the encoder is replaced with a pretrained ResNet-34 network. To minimize the dice coefficient loss function, we optimize the parameters in the neural network by using an adaptive moment optimizer called AdamW. Additionally, we use a systematic method to find the optimum learning rate instead of doing parametric sweeps. We used a â€œone-cycleâ€ training schedule based on cyclical learning rates to speed up the convergence. We evaluated the performance of our convolutional neural network on CFD, a pavement crack image dataset. Our method achieved an F1 score of about 96%. This is the best performance among all other algorithms tested on this dataset, outperforming the previous best method by a 1.7% margin.<br>Submitted 10 January, 2020; v1 submitted 7 January, 2020; originally announced January 2020.<br>Comments: 9 pages, 6 figures</p>
<h3 id="1-æè¿°"><a href="#1-æè¿°" class="headerlink" title="1.æè¿°"></a>1.æè¿°</h3><p>æå‡ºçš„ç¥ç»ç½‘ç»œç»“æ„æ˜¯ä¸€ä¸ªæ”¹è¿›çš„ U-Netï¼Œå…¶ç¼–ç å™¨è¢«ä¸€ä¸ªé¢„å…ˆè®­ç»ƒçš„ ResNet-34 ç½‘ç»œæ‰€å–ä»£ã€‚ä½¿ç”¨ dice coefficient ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œä½¿ç”¨ AdamW è‡ªé€‚åº”çŸ©ä¼˜åŒ–å™¨æ¥ä¼˜åŒ–ç¥ç»ç½‘ç»œä¸­çš„å‚æ•°ã€‚è¿˜ä½¿ç”¨äº†ä¸€ä¸ªç³»ç»Ÿçš„æ–¹æ³•æ¥å¯»æ‰¾æœ€ä½³å­¦ä¹ ç‡ã€‚æœ€ç»ˆ F1 Score ä¸º 91%ã€‚</p>
<h3 id="2-æ•°æ®é›†-1"><a href="#2-æ•°æ®é›†-1" class="headerlink" title="2.æ•°æ®é›†"></a>2.æ•°æ®é›†</h3><p>ä½¿ç”¨ CFD(320x480)æ•°æ®é›†ï¼Œç”¨å¦‚ä¸‹æ–¹æ³•åšäº†æ•°æ®å¢å¼ºã€‚ä»¥ 20 pixels ä¸ºæ­¥é•¿ï¼Œåœ¨å›¾åƒçš„æ°´å¹³å’Œå‚ç›´è½´ä¸Šåˆ†åˆ«è£å‰ªå‡º 128x128ã€256x256ã€320x320 å°ºå¯¸çš„å›¾ç‰‡ï¼Œåœ¨å…¶å¯¹åº”çš„ ground truth ä¹ŸåšåŒæ ·çš„æ“ä½œã€‚æœ€ç»ˆå›¾ç‰‡å¯¹åº”å°ºå¯¸æ•°é‡å¦‚ä¸‹ï¼š<br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289462960-d4bafb1a-94f6-4ae5-bbe3-4c27ee8605e9.png#align=left&display=inline&height=285&name=1579531826428.png&originHeight=285&originWidth=774&size=62694&status=done&style=none&width=774" alt="1579531826428.png"><br>åœ¨è®­ç»ƒæ—¶ï¼Œæ¯å¼ å›¾ç‰‡æ‰§è¡Œä¸‰ç§ç±»å‹çš„æ•°æ®å¢å¼ºï¼šæ—‹è½¬ã€ç¿»è½¬ã€æ”¹å˜äº®åº¦ã€‚</p>
<h3 id="3-æ–¹æ³•-1"><a href="#3-æ–¹æ³•-1" class="headerlink" title="3.æ–¹æ³•"></a>3.æ–¹æ³•</h3><ul>
<li>ResNet34 base U-Net</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289472986-5eac99b4-e019-4895-a683-f180106a6515.png#align=left&display=inline&height=809&name=1579532052186.png&originHeight=809&originWidth=1118&size=181311&status=done&style=none&width=1118" alt="1579532052186.png"><br>ResNet34 æ˜¯åœ¨ ImageNet ä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œå»é™¤å…¶æœ€åçš„å¹³å‡æ± åŒ–å±‚å’Œå…¨è¿æ¥å±‚ã€‚æ¥ä¸Šäº†ä¸Šé‡‡æ ·æ¨¡å—ã€‚è§£ç å™¨ç”±é‡å¤ä¸Šé‡‡æ ·å—(å›¾ 2 ä¸­çš„æ´‹çº¢è‰²å’Œç´«è‰²å—)ç»„æˆï¼Œå®ƒå°†è¾“å‡ºæ¿€æ´»çš„ç©ºé—´åˆ†è¾¨ç‡æé«˜ä¸€å€ï¼ŒåŒæ—¶å°†ç‰¹å¾é€šé“çš„æ•°é‡å‡åŠã€‚æ¯ä¸ªä¸Šé‡‡æ ·å±‚ç”± 1 ä¸ª BN å±‚ï¼ŒReLU å±‚å’Œ 1 ä¸ªè½¬ç½®å·ç§¯å±‚ç»„æˆï¼ˆ2*2kernel,2 strideï¼‰ã€‚åœ¨ BN å±‚ä¸ªè½¬ç½®å·ç§¯å±‚ä¹‹é—´æ·»åŠ äº† SCSE æ¨¡å—(concurrent spatial and channel squeeze and excitation module)ã€‚</p>
<ul>
<li>dice coefficient loss</li>
</ul>
<p>dice coefficient loss ç›¸å½“äº F1 scoreï¼Œå°†å…¶ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œç›¸å½“äºå¯¹ F1 åˆ†æ•°ç›´æ¥è¿›è¡Œä¼˜åŒ–ã€‚</p>
<h4 id="è®­ç»ƒ-1"><a href="#è®­ç»ƒ-1" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h4><ul>
<li>å‚æ•°åˆå§‹åŒ–ï¼šä¸‹æ–‡çš„åˆå§‹åŒ–æ–¹æ³•(é«˜æ–¯åˆ†å¸ƒï¼Œå…¶å‡å€¼ä¸º 0ã€æ–¹å·®ä¸º$2/n_l$ï¼Œå…¶ä¸­$n_l$ä¸ºå·ç§¯å±‚é€šé“æ•°ã€‚)ResNet34 éƒ¨åˆ†ä½¿ç”¨é¢„è®­ç»ƒå‚æ•°ã€‚</li>
</ul>
<p>K. He, X. Zhang, S. Ren, and J. Sun, â€œDelving deep into rectifiers:surpassing human-level performance on ImageNet classification,â€ in IEEE ICCV, Santiago, Chile, Dec. 2015.</p>
<ul>
<li>ä¼˜åŒ–å™¨ï¼šAdamW ä¼˜åŒ–å™¨($\lambda =0.01$, $\alpha$æ˜¯å­¦ä¹ ç‡, $\epsilon =10^{-8}$)</li>
</ul>
$$

\boldsymbol{\theta}_{t}=(1-\lambda) \boldsymbol{\theta}_{t-1}-\alpha\left(\frac{\widehat{\boldsymbol{m}_{t}}}{\sqrt{\widehat{\boldsymbol{v}}_{t}}+\epsilon}\right)


$$

<ul>
<li>å­¦ä¹ ç‡ï¼šä½¿ç”¨è¾ƒå¤§ç¯‡å¹…è®²å­¦ä¹ ç‡</li>
</ul>
<h3 id="4-æ•ˆæœ-1"><a href="#4-æ•ˆæœ-1" class="headerlink" title="4.æ•ˆæœ"></a>4.æ•ˆæœ</h3><ul>
<li>è¯„ä»·æ–¹æ³•</li>
</ul>
$$

\begin{aligned}

\operatorname{Pr} &=\frac{T P}{T P+F P} \

R e &=\frac{T P}{T P+F N} \

F 1 &=\frac{2 \times \text { Pr } \times R e}{\text { Pr }+R e}

\end{aligned}


$$

<p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289494552-405455e1-1c3f-45f2-b5e5-4c84c3622fa0.png#align=left&display=inline&height=490&name=1579535311307.png&originHeight=490&originWidth=720&size=162587&status=done&style=none&width=720" alt="1579535311307.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289503601-b5d143ee-6a1a-4a95-90f0-50860dd78a6e.png#align=left&display=inline&height=476&name=1579535328566.png&originHeight=476&originWidth=1431&size=484232&status=done&style=none&width=1431" alt="1579535328566.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289512376-6cb7882a-bf64-4801-9a00-d36e50fa332f.png#align=left&display=inline&height=585&name=1579535350811.png&originHeight=585&originWidth=1459&size=385116&status=done&style=none&width=1459" alt="1579535350811.png"></p>
<h2 id="3-CrackGAN-A-Labor-Light-Crack-Detection-Approach-Using-Industrial-Pavement-Images-Based-on-Generative-Adversarial-Learning"><a href="#3-CrackGAN-A-Labor-Light-Crack-Detection-Approach-Using-Industrial-Pavement-Images-Based-on-Generative-Adversarial-Learning" class="headerlink" title="3. CrackGAN: A Labor-Light Crack Detection Approach Using Industrial Pavement Images Based on Generative Adversarial Learning"></a>3. CrackGAN: A Labor-Light Crack Detection Approach Using Industrial Pavement Images Based on Generative Adversarial Learning</h2><p><a href="https://arxiv.org/abs/1909.08216" target="_blank" rel="external nofollow noopener noreferrer">arXiv:1909.08216</a>  [<a href="./pdf/1909.08216">pdf</a>, <a href="https://arxiv.org/format/1909.08216" target="_blank" rel="external nofollow noopener noreferrer">other</a>] cs.CV cs.LG eess.IV<br>Authors: <a href="https://arxiv.org/search/?searchtype=author&query=Zhang%2C+K" target="_blank" rel="external nofollow noopener noreferrer">Kaige Zhang</a>, <a href="https://arxiv.org/search/?searchtype=author&query=Zhang%2C+Y" target="_blank" rel="external nofollow noopener noreferrer">Yingtao Zhang</a>, <a href="https://arxiv.org/search/?searchtype=author&query=Cheng%2C+H" target="_blank" rel="external nofollow noopener noreferrer">Heng-Da Cheng</a><br>Abstract: Fully convolutional network is a powerful tool for per-pixel semantic segmentation/detection. However, it is problematic when coping with crack detection using industrial pavement images: the network may easily â€œconvergeâ€ to the status that treats all the pixels as background (BG) and still achieves a very good loss, named â€œAll Blackâ€ phenomenon, due to the data imbalance and the unavailability of accurate ground truths (GTs). To tackle this problem, we introduce crack-patch-only (CPO) supervision and generative adversarial learning for end-to-end training, which forces the network to always produce crack-GT images while reserves both crack and BG-image translation abilities by feeding a larger-size crack image into an asymmetric U-shape generator to overcome the â€œAll Blackâ€ issue. The proposed approach is validated using four crack datasets; and achieves state-of-the-art performance comparing with that of the recently published works in efficiency and accuracy.<br>Submitted 18 September, 2019; originally announced September 2019.</p>
<h3 id="1-ç®€è¿°-1"><a href="#1-ç®€è¿°-1" class="headerlink" title="1.ç®€è¿°"></a>1.ç®€è¿°</h3><p>FCN ç½‘ç»œæ˜¯ä¸€ä¸ªå¼ºæœ‰åŠ›çš„åƒç´ çº§åˆ†å‰²ç½‘ç»œï¼Œä½†ç”¨äºå·¥ä¸šçº§è·¯é¢å›¾åƒè£‚ç¼åˆ†å‰²æ˜¯æœ‰é—®é¢˜çš„ã€‚ç”±äºè£‚ç¼å’ŒèƒŒæ™¯çš„æ ·æœ¬ä¸¥é‡ä¸å¹³è¡¡ã€‚ç½‘ç»œå¾ˆå®¹æ˜“â€œæ”¶æ•›â€åˆ°å°†æ‰€æœ‰åƒç´ ä½œä¸ºèƒŒæ™¯(BG)çš„çŠ¶æ€ï¼Œä½†ä»ç„¶ä¼šæœ‰å¾ˆå¥½çš„æŸå¤±ï¼Œç§°ä¸ºâ€œAll Blackâ€ç°è±¡ã€‚<br>ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº† crack-patch-only(CPO)ç›‘ç£å’Œç«¯åˆ°ç«¯è®­ç»ƒçš„ç”Ÿæˆå¯¹æŠ—å­¦ä¹ ï¼Œè¿™è¿«ä½¿ç½‘ç»œåœ¨ä¿ç•™è£‚çº¹å’Œ BG å›¾åƒçš„åŒæ—¶ï¼Œå§‹ç»ˆç”Ÿæˆ crack-GT å›¾åƒã€‚<br>è¯¥ç®—æ³•é€šè¿‡å°†è¾ƒå¤§å°ºå¯¸çš„è£‚çº¹å›¾åƒè¾“å…¥éå¯¹ç§° u å½¢å‘ç”Ÿå™¨æ¥å…‹æœè£‚çº¹â€œAll Blackâ€çš„é—®é¢˜ã€‚<br><strong>è§£å†³</strong></p>
<ul>
<li>1.All Black é—®é¢˜ï¼šç½‘ç»œæ”¶æ•›åˆ°æ‰€æœ‰åƒç´ éƒ½æ˜¯èƒŒæ™¯çš„çŠ¶æ€</li>
<li>2.æå‡º crack-patch-only (CPO) supervision and generative adversarial</li>
</ul>
<p>learning</p>
<ul>
<li>åªéœ€è¦å°‘é‡åŠ³åŠ¨åŠ›æ ‡æ³¨çš„ GTsï¼Œå‡å°‘æ ‡æ³¨çš„åŠ³åŠ¨åŠ›ã€‚å³ä½¿ç½‘ç»œåœ¨å°å›¾ç‰‡å—ä¸Šè®­ç»ƒï¼Œä¹Ÿå¯ä»¥æœ‰æ•ˆçš„åœ¨å…¨å°ºå¯¸å›¾ç‰‡ä¸Šæ£€æµ‹ã€‚</li>
</ul>
<h3 id="2-æ•°æ®é›†-2"><a href="#2-æ•°æ®é›†-2" class="headerlink" title="2.æ•°æ®é›†"></a>2.æ•°æ®é›†</h3><p>è‡ªå»º CrackGAN dataset ï¼ˆ2048x4096 pixelï¼‰ï¼Œå®‰è£…åœ¨æ—¶é€Ÿ 100 å…¬é‡Œçš„æ±½è½¦é¡¶éƒ¨çš„çº¿æ‰«æå·¥ä¸šæ‘„åƒæœºæ‹æ‘„ï¼Œæ‘„åƒå¤´æ‰«æ 4.096 ç±³å®½çš„è·¯é¢ï¼Œæ¯æ‰«æä¸€æ¬¡ï¼Œå¾—åˆ° 2048Ã—4096 åƒç´ çš„è·¯é¢å›¾åƒï¼ˆ 1 pixel represents 1Ã—1 mm 2 areaï¼‰</p>
<h3 id="3-æ–¹æ³•-2"><a href="#3-æ–¹æ³•-2" class="headerlink" title="3.æ–¹æ³•"></a>3.æ–¹æ³•</h3><ul>
<li>æ¨¡å‹ç»“æ„</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289642708-74eae35f-a150-49f3-b0f0-29819de90534.png#align=left&display=inline&height=742&name=1579767560440.png&originHeight=742&originWidth=1229&size=198585&status=done&style=none&width=1229" alt="1579767560440.png"><br>D æ˜¯ä¸€ä¸ªé¢„è®­ç»ƒé‰´åˆ«å™¨ï¼Œå®ƒä»åªåœ¨ crack-GT patches ä¸Šè®­ç»ƒçš„ DC-GAN å¾—æ¥ã€‚<br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289651397-9012d8b8-b764-4159-9970-6b25f1937ec5.png#align=left&display=inline&height=555&name=1579768013248.png&originHeight=555&originWidth=708&size=129977&status=done&style=none&width=708" alt="1579768013248.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289659738-3f0ddf5f-6bdd-4cb6-9480-f17047591798.png#align=left&display=inline&height=690&name=1579768035344.png&originHeight=690&originWidth=1032&size=275838&status=done&style=none&width=1032" alt="1579768035344.png"></p>
<h4 id="è®­ç»ƒ-2"><a href="#è®­ç»ƒ-2" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h4><p>äº¤æ›¿ä¼˜åŒ–ä»¥ä¸‹ä¸¤ä¸ªç›®æ ‡ï¼š</p>
$$
\begin{aligned}
\max _{D} V(D, G) &=E_{x \sim p_{d}(x)}[\log D(x)] \
&+E_{z \sim p_{d}(z)}[\log (1-D(G(z)))] \
\max _{G} V(D, G) &=E_{z \sim p_{d}(z)}[\log (D(G(z)))]
\end{aligned}
$$

<h3 id="4-æ•ˆæœ-2"><a href="#4-æ•ˆæœ-2" class="headerlink" title="4.æ•ˆæœ"></a>4.æ•ˆæœ</h3><p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289670264-468eb1f9-ab39-4fc2-8ee2-7512e483a850.png#align=left&display=inline&height=644&name=1579768935867.png&originHeight=644&originWidth=757&size=224662&status=done&style=none&width=757" alt="1579768935867.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289678157-4f026562-8e10-4b42-ae3f-ee48a759e859.png#align=left&display=inline&height=318&name=1579768988464.png&originHeight=318&originWidth=756&size=106737&status=done&style=none&width=756" alt="1579768988464.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289685667-823b991a-5353-4af0-a2a5-0f806bf80bcf.png#align=left&display=inline&height=207&name=1579768973457.png&originHeight=207&originWidth=669&size=55765&status=done&style=none&width=669" alt="1579768973457.png"><br>åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ·±å±‚ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œå‘½åä¸º CrackGANï¼Œç”¨äºè·¯é¢è£‚ç¼æ£€æµ‹ã€‚è¯¥æ–¹æ³•è§£å†³äº†åŸºäº fcn çš„åƒç´ çº§è£‚çº¹æ£€æµ‹ä¸­å­˜åœ¨çš„å…¨é»‘é—®é¢˜ã€‚å¼•å…¥äº†å…·æœ‰ CPO ç›‘ç£çš„ç”Ÿæˆå¼å¯¹æŠ—æŸå¤±ï¼Œä½¿ç›®æ ‡å‡½æ•°è§„èŒƒåŒ–ï¼Œå…‹æœäº†ç±»è£‚çº¹å¯¹è±¡è®¾è®¡ä¸­å›ºæœ‰çš„æ•°æ®ä¸å¹³è¡¡é—®é¢˜ã€‚æå‡ºäº†åŸºäº cpo ç›‘ç£è®­ç»ƒçš„ BG å›¾åƒéå¯¹ç§° u å½¢ç»“æ„ã€‚æ­¤å¤–ï¼Œè¯¥ç½‘ç»œè¢«è®¾è®¡æˆ FCNï¼Œå¯ä»¥ç”¨å°å›¾åƒå—è¿›è¡Œè®­ç»ƒï¼Œä½†å¯ä»¥æ— ç¼åœ°å¤„ç†å…¨å°ºå¯¸å›¾åƒã€‚å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸æœ€è¿‘å‘è¡¨çš„æ–‡çŒ®è¿›è¡Œäº†æ¯”è¾ƒï¼Œå–å¾—äº†è¾ƒå¥½çš„æ•ˆæœã€‚æ­¤å¤–ï¼Œæ¥å—åŸŸç¥ç»å…ƒç‰¹æ€§çš„ç†è®ºåˆ†æå¯ä»¥ç”¨æ¥è§£é‡Šæ·±åº¦å­¦ä¹ ä¸­çš„è®¸å¤šç°è±¡ï¼Œå¦‚è¯­ä¹‰åˆ†å‰²[6]çš„è¾¹ç•Œæ¨¡ç³Šã€ç”Ÿæˆçš„å›¾åƒç”¨ GAN[33]ã€[35]æ¨¡ç³Šç­‰ã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼Œæœ¬æ–‡æ‰€è®¨è®ºçš„å¯¹æ¯ä¸ªç¥ç»å…ƒç‰¹æ€§çš„åˆ†æå°†æˆä¸ºæœªæ¥è®¾è®¡æœ‰æ•ˆçš„ç¥ç»ç½‘ç»œçš„å¸¸è§„æ–¹æ³•ã€‚</p>
<h2 id="4-A-Cost-Effective-Solution-for-Road-Crack-Inspection-using-Cameras-and-Deep-Neural-Networks"><a href="#4-A-Cost-Effective-Solution-for-Road-Crack-Inspection-using-Cameras-and-Deep-Neural-Networks" class="headerlink" title="4. A Cost Effective Solution for Road Crack Inspection using Cameras and Deep Neural Networks"></a>4. A Cost Effective Solution for Road Crack Inspection using Cameras and Deep Neural Networks</h2><p><a href="https://arxiv.org/abs/1907.06014" target="_blank" rel="external nofollow noopener noreferrer">arXiv:1907.06014</a>  [<a href="./pdf/1907.06014">pdf</a>] cs.CV cs.LG eess.IV<br>Authors: <a href="https://arxiv.org/search/?searchtype=author&query=Mei%2C+Q" target="_blank" rel="external nofollow noopener noreferrer">Qipei Mei</a>, <a href="https://arxiv.org/search/?searchtype=author&query=G%C3%BCl%2C+M" target="_blank" rel="external nofollow noopener noreferrer">Mustafa GÃ¼l</a><br>Abstract: Automatic crack detection on pavement surfaces is an important research field in the scope of developing an intelligent transportation infrastructure system. In this paper, a cost effective solution for road crack inspection by mounting commercial grade sport camera, GoPro, on the rear of the moving vehicle is introduced. Also, a novel method called ConnCrack combining conditional Wasserstein generative adversarial network and connectivity maps is proposed for road crack detection. In this method, a 121-layer densely connected neural network with deconvolution layers for multi-level feature fusion is used as generator, and a 5-layer fully convolutional network is used as discriminator. To overcome the scattered output issue related to deconvolution layers, connectivity maps are introduced to represent the crack information within the proposed ConnCrack. The proposed method is tested on a publicly available dataset as well our collected data. The results show that the proposed method achieves state-of-the-art performance compared with other existing methods in terms of precision, recall and F1 score.<br>Submitted 22 October, 2019; v1 submitted 13 July, 2019; originally announced July 2019.</p>
<h3 id="1-ç®€è¿°-2"><a href="#1-ç®€è¿°-2" class="headerlink" title="1.ç®€è¿°"></a>1.ç®€è¿°</h3><p>ä½¿ç”¨ GoPro è¿åŠ¨ç›¸æœºé‡‡é›†å›¾åƒã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆæ¡ä»¶ç“¦ç‘Ÿæ–¯å¦ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(conditional Wasserstein generative adversarial network)å’Œè¿é€šå›¾çš„é“è·¯è£‚ç¼æ£€æµ‹æ–¹æ³•ã€‚<br>è¯¥æ–¹æ³•ä»¥ 121 å±‚å¯†é›†è¿æ¥çš„ç¥ç»ç½‘ç»œå’Œ 5 å±‚å…¨å·ç§¯ç½‘ç»œä¸ºé‰´åˆ«å™¨ï¼Œåˆ©ç”¨åå·ç§¯å±‚è¿›è¡Œå¤šå±‚ç‰¹å¾èåˆã€‚ä¸ºäº†å…‹æœä¸åå·ç§¯å±‚ç›¸å…³çš„ç¦»æ•£è¾“å‡ºé—®é¢˜ï¼Œå¼•å…¥äº†è¿é€šå›¾æ¥è¡¨ç¤ºæ‹Ÿåˆè£‚çº¹å†…çš„è£‚çº¹ä¿¡æ¯ã€‚<br>ä¸ç°æœ‰çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨ç²¾åº¦ã€æŸ¥å…¨ç‡å’Œ F1 åˆ†æ•°æ–¹é¢éƒ½è¾¾åˆ°äº†æœ€æ–°çš„æ°´å¹³ã€‚</p>
<h3 id="2-æ•°æ®é›†-3"><a href="#2-æ•°æ®é›†-3" class="headerlink" title="2.æ•°æ®é›†"></a>2.æ•°æ®é›†</h3><p>ç›¸æœºåæŒ¡é£ç»ç’ƒå®‰æ”¾ï¼š<br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289793315-a2ad19a5-6990-44cf-938b-3e9e8e263cde.png#align=left&display=inline&height=508&name=1579774075928.png&originHeight=508&originWidth=931&size=371135&status=done&style=none&width=931" alt="1579774075928.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289800945-6ff72f10-5d76-4050-a90e-c7c3c3400f37.png#align=left&display=inline&height=591&name=1579774136892.png&originHeight=591&originWidth=715&size=139637&status=done&style=none&width=715" alt="1579774136892.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289808288-dba9c083-6301-4cb0-8bf0-4c9bab1f458e.png#align=left&display=inline&height=379&name=1579774163742.png&originHeight=379&originWidth=924&size=68418&status=done&style=none&width=924" alt="1579774163742.png"><br>ä½¿ç”¨åæŒ‚è½½é…ç½®æœ‰ä¸‰ä¸ªä¸»è¦åŸå› :</p>
<ul>
<li>æŒ¡é£ç»ç’ƒå¯ä»¥åå°„æ±½è½¦å†…éƒ¨çš„å…‰çº¿ï¼Œé™ä½å‰é¢å®‰è£…é…ç½®çš„å›¾åƒè´¨é‡ã€‚</li>
<li>å‰æ‘„åƒå¤´ç¦»åœ°é¢è¾ƒè¿œï¼Œå®ƒçš„å¤§éƒ¨åˆ†è§†åœº(FOV)è¢«æ±½è½¦çš„å¼•æ“ç›–æŒ¡ä½äº†ã€‚å› æ­¤ï¼Œå‰é¢çš„å®‰è£…é…ç½®ç‰ºç‰²äº†å¤ªå¤šçš„ç©ºé—´åˆ†è¾¨ç‡ä¸æˆ‘ä»¬ä¸Šé¢çš„åˆ†æã€‚</li>
<li>æˆ‘ä»¬çš„æœ€ç»ˆç›®æ ‡æ˜¯åœ¨è½¦è¾†ä¸Šç›´æ¥ä½¿ç”¨å¤‡ç”¨æ‘„åƒå¤´è¿›è¡Œè¡Œè½¦æ—¶çš„è£‚çº¹æ£€æµ‹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸éœ€è¦å®‰è£…ä»»ä½•å¤–éƒ¨è®¾å¤‡ã€‚</li>
</ul>
<p>æ•°æ®æ˜¯åœ¨è½¦è¾†ä»¥ 40 ~ 80 å…¬é‡Œ/å°æ—¶çš„é€Ÿåº¦è¡Œé©¶æ—¶é‡‡é›†çš„ï¼Œç›¸æœºé‡‡ç”¨ 240 å¸§/ç§’çš„å¸§ç‡å’Œ 1/3840 ç§’çš„å¿«é—¨é€Ÿåº¦ï¼Œæ¯ 6 å¸§æå–ä¸€æ¬¡å›¾åƒã€‚æœ€ç»ˆåœ¨ Edmonton, Canada ä¸åŒè·¯é¢é‡‡é›† 3 ä¸ªå°æ—¶å›¾åƒï¼Œæ„é€  EdmCrack600 æ•°æ®é›†ã€‚è¿™æ˜¯ç›®å‰æœ€å¤§çš„æ•°æ®é›†ã€‚</p>
<ul>
<li>æ•°æ®é›†å¯¹æ¯”</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289816059-d65037fb-038a-48aa-beb5-c9ad62352d4a.png#align=left&display=inline&height=342&name=1579774626654.png&originHeight=342&originWidth=1056&size=92325&status=done&style=none&width=1056" alt="1579774626654.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289823356-6479bc92-a320-4f50-bdcd-56c31a808890.png#align=left&display=inline&height=355&name=1579774649721.png&originHeight=355&originWidth=1049&size=99639&status=done&style=none&width=1049" alt="1579774649721.png"></p>
<h3 id="3-æ–¹æ³•-3"><a href="#3-æ–¹æ³•-3" class="headerlink" title="3.æ–¹æ³•"></a>3.æ–¹æ³•</h3><ul>
<li>ConnCrack</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289830659-701a7f3e-d3d0-4b23-b83e-ba529006bb6b.png#align=left&display=inline&height=455&name=1579774743826.png&originHeight=455&originWidth=959&size=126703&status=done&style=none&width=959" alt="1579774743826.png"></p>
<ul>
<li>ç”Ÿæˆå™¨ï¼šcWGAN<br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289838669-ad7c58cc-0249-4996-9e74-0367342c7f8a.png#align=left&display=inline&height=769&name=1579775914595.png&originHeight=769&originWidth=1497&size=232233&status=done&style=none&width=1497" alt="1579775914595.png"></li>
</ul>
<h4 id="è®­ç»ƒ-3"><a href="#è®­ç»ƒ-3" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h4><ul>
<li>loss function</li>
</ul>
$$

\begin{aligned}

&L_{c \mathrm{WG}, A N}(G, D)=E_{x, y}[D(x, y)]-E_{x}[D(x, G(x))]\

&G^{*}=\arg \min _{G} \max _{D}\left(\lambda L_{c W G A N}(G, D)+L_{\text {content }}(G)\right)

\end{aligned}


$$

<ul>
<li>é¢„è®­ç»ƒ</li>
</ul>
<p>åœ¨ ImageNet å’Œ CFD æ•°æ®é›†</p>
<p>å­¦ä¹ ç‡ï¼š$1x10^{-6}$</p>
<ul>
<li>EdmCrack600 æ•°æ®é›†</li>
</ul>
<p>å­¦ä¹ ç‡ï¼š$1x10^{-5}$ï¼Œ Î» is set to$5Ã—10^{-6}$</p>
<h3 id="4-æ•ˆæœ-3"><a href="#4-æ•ˆæœ-3" class="headerlink" title="4.æ•ˆæœ"></a>4.æ•ˆæœ</h3><ul>
<li>é¢„è®­ç»ƒæ•°æ®</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289848262-14d7662c-08a0-466b-bb62-b2fb6159ae65.png#align=left&display=inline&height=717&name=1579776227118.png&originHeight=717&originWidth=560&size=110887&status=done&style=none&width=560" alt="1579776227118.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289856255-e6c46197-368d-4cfd-938f-b71ad98e70e7.png#align=left&display=inline&height=497&name=1579776249755.png&originHeight=497&originWidth=720&size=137067&status=done&style=none&width=720" alt="1579776249755.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289863968-3869cfa3-a9bc-479e-a959-ffe7cb4b58d9.png#align=left&display=inline&height=500&name=1579776334046.png&originHeight=500&originWidth=950&size=235440&status=done&style=none&width=950" alt="1579776334046.png"></p>
<ul>
<li>EdmCrack600 æ•°æ®é›†<br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289871093-3e115685-d79d-4bf7-8575-2a75c5f2aa75.png#align=left&display=inline&height=843&name=1579776609645.png&originHeight=843&originWidth=451&size=153195&status=done&style=none&width=451" alt="1579776609645.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289879304-7a112d2a-9c7f-4ac9-bf11-2103ea9afecc.png#align=left&display=inline&height=431&name=1579776623377.png&originHeight=431&originWidth=796&size=118722&status=done&style=none&width=796" alt="1579776623377.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289887108-0a6f61bb-2293-4702-920a-3e27d8ab659a.png#align=left&display=inline&height=807&name=1579776697993.png&originHeight=807&originWidth=1088&size=456145&status=done&style=none&width=1088" alt="1579776697993.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289895666-f21f28fb-384a-4007-9c55-0408d506c202.png#align=left&display=inline&height=864&name=1579776714014.png&originHeight=864&originWidth=896&size=90276&status=done&style=none&width=896" alt="1579776714014.png"></li>
</ul>
<h2 id="5-FPCNet-Fast-Pavement-Crack-Detection-Network-Based-on-Encoder-Decoder-Architecture"><a href="#5-FPCNet-Fast-Pavement-Crack-Detection-Network-Based-on-Encoder-Decoder-Architecture" class="headerlink" title="5.FPCNet: Fast Pavement Crack Detection Network Based on Encoder-Decoder Architecture"></a>5.FPCNet: Fast Pavement Crack Detection Network Based on Encoder-Decoder Architecture</h2><p><a href="https://arxiv.org/abs/1907.02248" target="_blank" rel="external nofollow noopener noreferrer">arXiv:1907.02248</a>  [<a href="./pdf/1907.02248">pdf</a>, <a href="https://arxiv.org/format/1907.02248" target="_blank" rel="external nofollow noopener noreferrer">other</a>] cs.CV<br>Authors: <a href="https://arxiv.org/search/?searchtype=author&query=Liu%2C+W" target="_blank" rel="external nofollow noopener noreferrer">Wenjun Liu</a>, <a href="https://arxiv.org/search/?searchtype=author&query=Huang%2C+Y" target="_blank" rel="external nofollow noopener noreferrer">Yuchun Huang</a>, <a href="https://arxiv.org/search/?searchtype=author&query=Li%2C+Y" target="_blank" rel="external nofollow noopener noreferrer">Ying Li</a>, <a href="https://arxiv.org/search/?searchtype=author&query=Chen%2C+Q" target="_blank" rel="external nofollow noopener noreferrer">Qi Chen</a><br>Abstract: Timely, accurate and automatic detection of pavement cracks is necessary for making cost-effective decisions concerning road maintenance. Conventional crack detection algorithms focus on the design of single or multiple crack features and classifiers. However, complicated topological structures, varying degrees of damage and oil stains make the design of crack features difficult. In addition, the contextual information around a crack is not investigated extensively in the design process. Accordingly, these design features have limited discriminative adaptability and cannot fuse effectively with the classifiers. To solve these problems, this paper proposes a deep learning network for pavement crack detection. Using the Encoder-Decoder structure, crack characteristics with multiple contexts are automatically learned, and end-to-end crack detection is achieved. Specifically, we first propose the Multi-Dilation (MD) module, which can synthesize the crack features of multiple context sizes via dilated convolution with multiple rates. The crack MD features obtained in this module can describe cracks of different widths and topologies. Next, we propose the SE-Upsampling (SEU) module, which uses the Squeeze-and-Excitation learning operation to optimize the MD features. Finally, the above two modules are integrated to develop the fast crack detection network, namely, FPCNet. This network continuously optimizes the MD features step-by-step to realize fast pixel-level crack detection. Experiments are conducted on challenging public CFD datasets and G45 crack datasets involving various crack types under different shooting conditions. The distinct performance and speed improvements over all the datasets demonstrate that the proposed method outperforms other state-of-the-art crack detection methods.<br>Submitted 4 July, 2019; originally announced July 2019.</p>
<h3 id="1-ç®€è¿°-3"><a href="#1-ç®€è¿°-3" class="headerlink" title="1.ç®€è¿°"></a>1.ç®€è¿°</h3><p>é‡‡ç”¨ç¼–è¯‘ç å™¨ç»“æ„ï¼Œè‡ªåŠ¨å­¦ä¹ å¤šç§ç¯å¢ƒä¸‹çš„è£‚çº¹ç‰¹å¾ï¼Œå®ç°ç«¯åˆ°ç«¯çš„è£‚çº¹æ£€æµ‹ã€‚<br>å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº†å¤šæ‰©å±•(Multi-Dilation, MD)æ¨¡å—ï¼Œè¯¥æ¨¡å—å¯ä»¥é€šè¿‡ä¸å¤šä¸ªé€Ÿç‡çš„æ‰©å±•å·ç§¯æ¥åˆæˆå¤šä¸ªä¸Šä¸‹æ–‡å¤§å°çš„è£‚ç¼ç‰¹å¾ã€‚è¯¥æ¨¡å—å¾—åˆ°çš„è£‚çº¹ MD ç‰¹å¾å¯ä»¥æè¿°ä¸åŒå®½åº¦å’Œæ‹“æ‰‘ç»“æ„çš„è£‚çº¹ã€‚<br>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æå‡º Squeeze-and-Excitation(SEU)æ¨¡å—ï¼Œåˆ©ç”¨æŒ¤å‹-æ¿€åŠ±å­¦ä¹ æ“ä½œä¼˜åŒ– MD ç‰¹æ€§ã€‚æœ€åï¼Œå°†ä¸Šè¿°ä¸¤ä¸ªæ¨¡å—é›†æˆåœ¨ä¸€èµ·ï¼Œå¼€å‘äº†å¿«é€Ÿè£‚çº¹æ£€æµ‹ç½‘ç»œ FPCNetã€‚</p>
<h3 id="2-æ•°æ®é›†-4"><a href="#2-æ•°æ®é›†-4" class="headerlink" title="2.æ•°æ®é›†"></a>2.æ•°æ®é›†</h3><ul>
<li>CFD datasets</li>
<li>G45 crack datasets</li>
</ul>
<h3 id="3-æ–¹æ³•-4"><a href="#3-æ–¹æ³•-4" class="headerlink" title="3.æ–¹æ³•"></a>3.æ–¹æ³•</h3><p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289990838-6edcf3e6-a66e-47a6-aa0a-c6c0b97888f8.png#align=left&display=inline&height=315&name=1579782781244.png&originHeight=315&originWidth=804&size=25519&status=done&style=none&width=804" alt="1579782781244.png"></p>
<ul>
<li>Multi-Dilation (MD)</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580289998293-d8b74edf-f551-4847-b11b-f90cb02baf0d.png#align=left&display=inline&height=557&name=1579782800843.png&originHeight=557&originWidth=1320&size=99739&status=done&style=none&width=1320" alt="1579782800843.png"><br>MD æ¨¡å—é€šè¿‡ç»“åˆä¸åŒé€Ÿç‡çš„å¤šä¸ªæ‰©å±•å·ç§¯[23]å’Œä¸€ä¸ªå…¨å±€æ± ï¼Œæå–ä¸åŒä¸Šä¸‹æ–‡å¤§å°çš„è£‚ç¼ç‰¹å¾ï¼Œæ£€æµ‹ä¸åŒå®½åº¦å’Œæ‹“æ‰‘ç»“æ„çš„è£‚ç¼ã€‚</p>
<ul>
<li>rate=1:è¿™ç§å·ç§¯é€‚ç”¨äºè–„è€Œç®€å•çš„è£‚çº¹ï¼Œä½†ä¸èƒ½æœ‰æ•ˆåœ°æ£€æµ‹å®½è£‚çº¹å’Œæ‹“æ‰‘å¤æ‚çš„è£‚çº¹ã€‚</li>
<li>è¿™äº›è£‚çº¹å¯ä»¥ç”¨æ›´å¤§çš„ r å€¼(ä¾‹å¦‚ï¼Œ4)çš„è†¨èƒ€å·ç§¯æ¥é²æ£’æ£€æµ‹ã€‚</li>
<li>SE-Upsampling (SEU)</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580290008108-dcabbd52-3958-443b-842c-562c56b74b6b.png#align=left&display=inline&height=496&name=1579784610822.png&originHeight=496&originWidth=1352&size=140275&status=done&style=none&width=1352" alt="1579784610822.png"><br>å…·ä½“æ¥è¯´ï¼ŒMD ç‰¹å¾é¦–å…ˆé€šè¿‡è½¬ç½®å·ç§¯è¿›è¡Œä¸Šé‡‡æ ·ï¼Œä½¿å…¶åˆ†è¾¨ç‡æ¢å¤ 2 å€ï¼Œé€šé“æ•°å‡å°‘åˆ°åŸæ¥å€¼çš„ä¸€åŠã€‚æ¥ä¸‹æ¥ï¼ŒMC å…·æœ‰ä¸å›¾ 4 ç›¸åŒçš„åˆ†è¾¨ç‡ã€‚FPCNet çš„ç½‘ç»œç»“æ„ã€‚è¯¥æ–¹æ³•ä½¿ç”¨ 4 Convs(ä¸¤ä¸ª 33 ä¸ªå·ç§¯å’Œ ReLUs) +æœ€å¤§æ± ä½œä¸ºç¼–ç å™¨æ¥æå–ç‰¹å¾ã€‚æ¥ä¸‹æ¥ï¼Œä½¿ç”¨ MD æ¨¡å—è·å–å¤šä¸ªä¸Šä¸‹æ–‡å¤§å°çš„ä¿¡æ¯ã€‚éšåï¼Œ4 ä¸ª SEU æ¨¡å—ä½œä¸ºè§£ç å™¨è¿è¡Œã€‚H å’Œ W è¡¨ç¤ºå›¾åƒçš„åŸå§‹å¤§å°ã€‚çº¢è‰²ã€ç»¿è‰²å’Œè“è‰²ç®­å¤´åˆ†åˆ«è¡¨ç¤ºæœ€å¤§æ± ã€ç½®æ¢å·ç§¯å’Œ 11 ä¸ªå·ç§¯+ s å½¢ã€‚MCF è¡¨ç¤ºç¼–ç å™¨ä¸­æå–çš„å¤šå·ç§¯ç‰¹å¾ï¼ŒMDF è¡¨ç¤º MD ç‰¹å¾ã€‚æ·»åŠ åˆ° MD ç‰¹æ€§ã€‚æ‰§è¡Œå…¨å±€å¹³å‡æ± ï¼Œä»æ·»åŠ çš„ MD ç‰¹æ€§ä¸­è·å¾—æ¯ä¸ªé€šé“çš„å…¨å±€ä¿¡æ¯ã€‚éšåï¼Œé€šè¿‡æŒ¤å‹æ“ä½œ(F sq)å¤„ç†å…¨å±€ä¿¡æ¯ã€‚ä½¿ç”¨å…¨è¿æ¥å±‚æ¥æŒ¤å‹å…·æœ‰ä¸€å®šæ¯”ä¾‹çš„é€šé“æ•°é‡(åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ¯”ä¾‹ä¸º 16)ï¼Œå¹¶ä½¿ç”¨ ReLU å±‚å¯¹è¾“å‡ºè¿›è¡Œéçº¿æ€§åŒ–ã€‚æˆ‘ä»¬åœ¨è¾“å‡ºç«¯è¿›è¡Œä¸€ä¸ªæ¿€åŠ±è¿‡ç¨‹(F ex)ï¼Œåˆ©ç”¨å…¨è¿é€šå±‚å°†å‹ç¼©åçš„è¾“å‡ºæ¢å¤åˆ°åŸæ¥çš„é€šé“æ•°ã€‚ä½¿ç”¨ sigmoid å±‚è·å–é€šé“æƒå€¼ã€‚è¾ƒå¤§çš„æƒå€¼è¡¨æ˜é€šé“ç‰¹å¾å¯¹è£‚çº¹æ£€æµ‹çš„è´¡çŒ®è¾ƒå¤§ã€‚æœ€åï¼Œå°†æ¯ä¸ª MD ç‰¹å¾ä¹˜ä¸Šç›¸åº”çš„æƒå€¼ï¼Œå¾—åˆ°æœ€ä¼˜çš„ MD ç‰¹å¾ã€‚</p>
<ul>
<li>FPCNet</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580290016611-40c033fa-b070-480c-823c-82f7b26d27a1.png#align=left&display=inline&height=386&name=1579784755668.png&originHeight=386&originWidth=1378&size=150146&status=done&style=none&width=1378" alt="1579784755668.png"></p>
<h4 id="è®­ç»ƒ-4"><a href="#è®­ç»ƒ-4" class="headerlink" title="è®­ç»ƒ"></a>è®­ç»ƒ</h4><ul>
<li>loss function: binary cross entropy (BCE) + dice coefficient loss</li>
</ul>
$$

\begin{aligned}

L\left(Y^{_}, Y\right)=& \frac{1}{N} \sum_{P \in N}\left(Y_{P}^{_} \cdot \lg Y_{P}+\left(1-Y_{P}^{*}\right) \cdot \lg \left(1-Y_{P}\right)\right.\

&+1-\frac{2 \times T P}{2 \times T P+F P+F N}

\end{aligned}


$$

<ul>
<li>ä¼˜åŒ–å™¨ï¼šSGD with Momentum (0.9) a batch size of 1 and a weight decay of 0.0001.</li>
<li>å­¦ä¹ ç‡ï¼šåˆå§‹ä¸º 0.01ï¼Œåœ¨ç¬¬ 50/80/110 epoch åˆ†åˆ«ç¼©å° 10 å€ï¼Œåœ¨ 120epoch ç»ˆæ­¢ã€‚</li>
</ul>
<h3 id="4-æ•ˆæœ-4"><a href="#4-æ•ˆæœ-4" class="headerlink" title="4.æ•ˆæœ"></a>4.æ•ˆæœ</h3><p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580290026327-15e20d70-e743-4720-9df6-10834663ab7b.png#align=left&display=inline&height=365&name=1579784862206.png&originHeight=365&originWidth=727&size=96125&status=done&style=none&width=727" alt="1579784862206.png"></p>
<ul>
<li>æ•ˆç‡</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580290034218-e311f4e5-780a-4d62-a112-da6e8f87b110.png#align=left&display=inline&height=588&name=1579785225006.png&originHeight=588&originWidth=743&size=77638&status=done&style=none&width=743" alt="1579785225006.png"><br><img src="https://cdn.nlark.com/yuque/0/2020/png/478234/1580290043477-7f63b6dd-ce9b-4679-92a1-753c274fdb47.png#align=left&display=inline&height=199&name=1579785243650.png&originHeight=199&originWidth=607&size=43348&status=done&style=none&width=607" alt="1579785243650.png"></p>
    </div>
  </div>
  
    <div class="copy-right">
      <div class="markdown-body">
        <blockquote>
        
        
          æœ¬æ–‡ä½œè€… : HeoLis <br>
        
        åŸæ–‡é“¾æ¥ : <a href="">https://ishero.net/%E8%B7%AF%E9%9D%A2%E8%A3%82%E7%BC%9D%E5%88%86%E5%89%B2%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0.html</a><br>
        ç‰ˆæƒå£°æ˜ : æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="external nofollow noopener noreferrer">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼
        </blockquote>
      </div>
    </div>
  
  
  
    <div class="social-share" style="margin-top: -2rem" data-wechat-qrcode-title="<p>å¾®ä¿¡æ‰«ä¸€æ‰«</p>" data-wechat-qrcode-helper="<p>å¾®ä¿¡å³ä¸Šè§’, æ‰«ä¸€æ‰«åˆ†äº«</p>" data-sites="qzone, qq, weibo, wechat, douban, google, facebook, twitter">
  <span style="color: #6b7487; font-size: 1.4rem;">åˆ†äº«åˆ°: </span>
</div>
<script src="https://cdn.bootcss.com/social-share.js/1.0.16/js/social-share.min.js" async></script>
  

  
    <div id="reward">
  
    <p id="reward-meta">å­¦ä¹ ã€è®°å½•ã€åˆ†äº«ã€è·å¾—</p>
  
  <button id="reward-btn">
    
    <span>æ‰“èµ</span>
  </button>
  <div id="reward-qrcode">
    
      <div class="reward-qrcode--container">
        <img class="qrcode-img" src="/images/donate-qr.png" alt="å¾®ä¿¡æ‰«ä¸€æ‰«, å‘æˆ‘æŠ•é£Ÿ">
        <p class="qrcode-meta">å¾®ä¿¡æ‰«ä¸€æ‰«, å‘æˆ‘æŠ•é£Ÿ</p>
      </div>
    
  </div>

</div>

<script>
  (() => {
    let button = document.querySelector('#reward-btn'),
      qrcode = document.querySelector('#reward-qrcode'),
      display = false;
    
    button.addEventListener('click', () => {
      qrcode.style.display = display ? 'none' : 'block'
      display = !display
    }, false)
  })()
</script>
  

  <div class="article-footer">
    <div class="article-meta pull-left">
      <span>
        
          <i class="iconfont icon-06tags"></i>æ ‡ç­¾: 
          
          <span class="span--tag">
            <a href="/tags/%E7%AC%94%E8%AE%B0/">
              #ç¬”è®°
            </a>
          </span>
          
        
      </span>
    </div>
    <div class="article-meta pull-right">
    </div>
  </div>
</div>


  <aside id="sidebar">
    <p id="sidebar-header"></p>
    <ol id="sidebar-toc"></ol>
  </aside>
  <script async>setTimeout(generateToc, 10);</script>



  <nav class="post-navigation">
    
      <div class="nav-pre">
        <i class="iconfont icon-prev"></i>
        ä¸Šä¸€ç¯‡:
        <a href="/Pavement%20Crack%20Segmentation%20Paper.html" target="_self">Pavement Crack Segmentation Paper</a>
      </div>
    
    
      <div class="nav-next">
        ä¸‹ä¸€ç¯‡:
        <a href="/%E9%AB%98%E6%95%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1II.html" target="_self">é«˜æ•ˆç¥ç»ç½‘ç»œè®¾è®¡II</a>
        <i class="iconfont icon-next"></i>
      </div>
    
  </nav>

   

  
    <script defer>
const valineAPI = (() => {
  try {
    AV.init("Epge4Qisj9i3E08wl1q1cSWB-gzGzoHsz", "ClV5c29GDRy9RkLPqrac09OT");
  } catch(error) {}
  const isExist = (identity) => {
    identity = identity || getRealPath();
    let query = new AV.Query('Timer');
    return new Promise((resolve, reject) => {
      query.equalTo("identity", identity);
      query.find().then(results => {
        resolve(results.length > 0);
      }, error => reject(error));
    })
  }

  const _get = (identity) => {
    let query = null;
    if(identity && identity instanceof Array){
      let querys = [];
      for(let i = 0; i < identity.length; ++i) {
        querys[i] = new AV.Query('Timer');
        querys[i].equalTo('identity', identity[i]);
      }
      query = AV.Query.or.apply(null ,querys);
    } else {
      identity = identity || getRealPath();
      query = new AV.Query("Timer");
      query.equalTo("identity", identity);
    }

    return new Promise((resolve, reject) => {
      query.find()
      .then(results => resolve(results))
      .catch(error => reject(error))
    })
  }

  const create = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
      let Todo = AV.Object.extend('Timer');
      let todo = new Todo();
      todo.set("times", 1);
      todo.set("identity", identity);
      todo.save().then(res => resolve(true), error => reject(error));
    })
  }

  const update = (identity) => {
    identity = identity || getRealPath();
    return new Promise((resolve, reject) => {
      let query = new AV.Query('Timer');
      query.equalTo("identity", identity);
      query.find().then(todos => {
        todos.forEach(todo => {
          todo.set("times", todo.attributes.times + 1);
        });
        return AV.Object.saveAll(todos);
      }).then(todos => resolve(true), error => reject(error));
    })
  }

  return {
    isExist,
    _get,
    update,
    create
  }
})()

const calcAndWriteTimes = () => {
  let isPost = true;

  let timerAllDOM = document.querySelectorAll(".article-timer");

  if(isPost) {
    let identity = timerAllDOM[0].getAttribute("data-identity");
    valineAPI.isExist(identity)
    .then(exist => {
      if(exist) {
        return valineAPI.update(identity);
      }
      return new Promise(resolve => resolve(true));
    })
    .then( succuess => valineAPI._get(identity))
    .then( result => timerAllDOM[0].innerText = result[0].attributes.times)
    .catch(error => console.log(error.message))
    return ;
  }

  let timerDOMCache = {};

  for(let timerDOM of timerAllDOM) {
    let identity = timerDOM.getAttribute("data-identity");
    if(timerDOMCache.hasOwnProperty(identity)){
      timerDOMCache[identity].dom.push(timerDOM);
    }else{
      timerDOMCache[identity] = {
        dom: [timerDOM],
        times: undefined
      };
    }
  }

  let identities = Object.keys(timerDOMCache);
  valineAPI._get(identities).then(results => {
    for(let result of results) {
      let {identity, times} = result.attributes;
      timerDOMCache[identity].times = times;
      timerDOMCache[identity].dom.map(item => item.innerText = times);
    }
    for(let identity of identities) {
      if(timerDOMCache[identity].times){
        continue;
      }
      timerDOMCache[identity].dom.map(item => item.innerText = 1);
      valineAPI.create(identity);
    }
  }).catch(error => console.log(error.message))
}

if(true){
  calcAndWriteTimes();
}
</script>
   

</div>



      <footer>
  <p class="site-info">
    åšå®¢å·²èŒèŒå“’è¿è¡Œ<span id="time-to-now"></span><span class="my-face">(â—'â—¡'â—)ï¾‰â™¥</span>
    <br>
    Theme - <a href="https://github.com/dongyuanxin/theme-bmw" target="_blank" rel="external nofollow noopener noreferrer">BMW</a> | Made With ğŸ’— | Powered by <a href="https://godbmw.com/" target="_blank" rel="external nofollow noopener noreferrer">GodBMW</a>
    <br>
    ICPè¯:<a href="http://www.beian.miit.gov.cn" target="_blank" rel="external nofollow noopener noreferrer">ç²¤ICPå¤‡19011977å·-1</a> 
  </p>
</footer>



<script>
const timeToNowDOM = document.querySelector("#time-to-now");
const startTimestamp = new Date(2017, 8, 20).getTime();

const updateTimeStr = () => {
  let offset = parseInt(
      (new Date().getTime() - startTimestamp) / 1000,
      10
    ),
    day = Math.floor(offset / 86400),
    hour = Math.floor((offset % 86400) / 3600),
    minute = Math.floor(((offset % 86400) % 3600) / 60),
    second = Math.floor(((offset % 86400) % 3600) % 60);
  timeToNowDOM.innerHTML =
    day + "å¤©" + hour + "å°æ—¶" + minute + "åˆ†é’Ÿ" + second + "ç§’";
  setTimeout(updateTimeStr, 500);
}

setTimeout(updateTimeStr, 500);
</script>


      <div class="back-to-top hidden">
  <span>
    <i class="iconfont icon-60"></i><span></span>%
  </span>
</div>

<script>
const updateIconToTop = percent => {
  let dom = document.querySelector(".back-to-top span span");
  dom.innerText = percent;
  if(percent < 1) {
    document.querySelector(".back-to-top").className = "back-to-top hidden";
  } else {
    document.querySelector(".back-to-top").className = "back-to-top";
  }
}

const handleScoll = () => {
  let isRunning = false;
  return () => {
    if (isRunning) return;
    isRunning = true;
    window.requestAnimationFrame(timestamp => {
      let scrollTop =
          document.documentElement.scrollTop || document.body.scrollTop,
        scrollHeight =
          document.documentElement.scrollHeight ||
          document.body.scrollHeight,
        clientHeight =
          document.documentElement.clientHeight ||
          document.body.clientHeight;
      isRunning = false;
      if (scrollTop <= 1) {
        updateIconToTop(0);
        return;
      }
      if (scrollTop + clientHeight >= scrollHeight) {
        updateIconToTop(100);
      } else {
        updateIconToTop(parseInt(
          100 * scrollTop / (scrollHeight - clientHeight),
          10
        ));
      }
    });
  };
}

const backToTop = () => {
  let scrollTop =
      document.documentElement.scrollTop || document.body.scrollTop,
    delay = 10,
    time = 200;
  if (scrollTop <= 20) {
    document.documentElement.scrollTop = 0;
    document.body.scrollTop = 0;
    return;
  }
  let step = Math.ceil(scrollTop * delay / time);
  let timer = setInterval(() => {
    scrollTop =
      document.documentElement.scrollTop || document.body.scrollTop;
    if (scrollTop - step <= 0) {
      document.documentElement.scrollTop = 0;
      document.body.scrollTop = 0;
      clearInterval(timer);
    } else {
      document.documentElement.scrollTop = scrollTop - step;
      document.body.scrollTop = scrollTop - step;
    }
  }, delay);
}

document.addEventListener("scroll", handleScoll(), false);

document.querySelector(".back-to-top").addEventListener("click", backToTop, false);

</script>

    </div>

    
      <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
<script>
  (() => {
    const mathjaxConfig = {
      showProcessingMessages: false, //å…³é—­jsåŠ è½½è¿‡ç¨‹ä¿¡æ¯
      messageStyle: "none", //ä¸æ˜¾ç¤ºä¿¡æ¯
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [["$", "$"], ["\\(", "\\)"]], //è¡Œå†…å…¬å¼é€‰æ‹©ç¬¦
        displayMath: [["$$", "$$"], ["\\[", "\\]"]], //æ®µå†…å…¬å¼é€‰æ‹©ç¬¦
        skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //é¿å¼€æŸäº›æ ‡ç­¾
      },
      "HTML-CSS": {
        availableFonts: ["STIX", "TeX"], //å¯é€‰å­—ä½“
        showMathMenu: false //å…³é—­å³å‡»èœå•æ˜¾ç¤º
      }
    }

    let mathjaxInterval = setInterval(() => {
      if(!window.MathJax){
        return;
      }
      window.MathJax.Hub.Config(mathjaxConfig)
      window.MathJax.Hub.Queue(["Typeset", MathJax.Hub, document.getElementById('app')])

      clearInterval(mathjaxInterval)
    }, 10)    
  })()
</script>
    

    <script src="https://cdn.bootcss.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script>
<script async>
  let fancyTimer = setInterval(function(){
    if(!window.$){
      return;
    }
    $(document).ready(function() {
      $(".post img").each(function () {
        if($(this).parent().get(0).tagName.toLowerCase() === "a") {
          return;
        }
        // $(this).attr("data-fancybox", "gallery"); // if you add 'data-fancybox', img will display after showed
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "gallery");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      });
      
      clearInterval(fancyTimer);
    });
  }, 10);
</script>

    
      
         
          <script src="/custom/script.js" async></script>
        
      
    
  </body>

</html>
